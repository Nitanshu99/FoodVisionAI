"""
Unified Training Script (With Class Filtering).

Trains the final classifier using the 'Clean Object' dataset
generated by yolo_processor.py.

Auto-optimized for hardware using auto_config.py
"""

import os
import numpy as np
import tensorflow as tf
import keras
from keras import callbacks
from pathlib import Path

# Local imports
import config
from src import augmentation, vision_model

# Auto-configuration for hardware optimization
try:
    from config.hardware import get_auto_config
    AUTO_CONFIG = get_auto_config()
    BATCH_SIZE = AUTO_CONFIG.get('TRAIN_BATCH_SIZE', config.BATCH_SIZE)
    print(f"\n‚úÖ Using auto-optimized settings:")
    print(f"   Batch Size: {BATCH_SIZE}")
    print(f"   GPU: {AUTO_CONFIG.get('GPU_NAME', 'N/A')}")
    print(f"   Precision: {AUTO_CONFIG.get('TRAIN_PRECISION', 'fp32')}")
except (ImportError, KeyError):
    print("\n‚ö†Ô∏è  Auto-config not found, using defaults")
    AUTO_CONFIG = None
    BATCH_SIZE = config.BATCH_SIZE

# --- CONFIGURATION ---
BASE_DIR = Path(__file__).resolve().parent
TRAIN_DIR = config.DATA_DIR / "yolo_processed" / "train"
VAL_DIR = config.DATA_DIR / "yolo_processed" / "val"
CLASS_NAMES_PATH = config.LABELS_PATH
FINAL_MODEL_PATH = config.MODEL_LOCAL_PATH  # Saving to Local Model path

# --- üö´ BLACKLIST: Add folders here to skip them ---
EXCLUDED_CLASSES = ["ASC321"]

# Performance Tuning
AUTOTUNE = tf.data.AUTOTUNE
IMG_SIZE = config.IMG_SIZE

def load_dataset(directory: Path, allowed_classes: list, is_training: bool = False):
    """Loads dataset and returns (dataset, class_names)."""
    if not directory.exists():
        raise FileNotFoundError(f"‚ùå Dataset not found at {directory}.")
        
    print(f"Loading data from: {directory}...")
    
    # Load Image Dataset with explicit class filtering
    ds = keras.utils.image_dataset_from_directory(
        directory,
        labels="inferred",
        label_mode="categorical",
        class_names=allowed_classes,
        color_mode="rgb",
        batch_size=BATCH_SIZE,
        image_size=IMG_SIZE,
        shuffle=True,
        seed=42
    )
    
    # --- FIX: Capture class_names before transformation ---
    class_names = ds.class_names
    
    # Apply Augmentation (Only for Training)
    if is_training:
        aug_pipeline = augmentation.get_augmentation_pipeline()
        ds = ds.map(
            lambda x, y: (aug_pipeline(x, training=True), y),
            num_parallel_calls=AUTOTUNE
        )
        
    ds = ds.prefetch(buffer_size=AUTOTUNE)
    
    # Return BOTH the dataset and the names
    return ds, class_names

def get_filtered_class_list(directory: Path):
    """Scans directory and removes blacklisted classes."""
    # Get all folder names
    all_classes = sorted([d.name for d in directory.iterdir() if d.is_dir()])
    
    # Filter
    valid_classes = [c for c in all_classes if c not in EXCLUDED_CLASSES]
    
    print(f"\nüîç Class Filtering Report:")
    print(f"   - Total Folders Found: {len(all_classes)}")
    print(f"   - Excluded: {EXCLUDED_CLASSES}")
    print(f"   - Final Class Count: {len(valid_classes)}")
    
    return valid_classes

def main():
    print(f"\nüöÄ Starting Unified Model Training on Device: {config.DEVICE}")
    print(f"TensorFlow Version: {tf.__version__}")
    print(f"üìÇ Training Data: {TRAIN_DIR}")

    # Enable TF32 for A6000 (2-3x faster matrix operations)
    if AUTO_CONFIG and AUTO_CONFIG.get('GPU_NAME', '').startswith('NVIDIA RTX A6000'):
        print(f"\n‚ö° Enabling TensorFloat-32 (TF32) for A6000...")
        tf.config.experimental.enable_tensor_float_32_execution(True)
        print(f"   TF32 enabled: 2-3x faster matrix operations!")

    # Enable XLA JIT compilation for faster execution
    print(f"‚ö° Enabling XLA JIT compilation...")
    tf.config.optimizer.set_jit(True)
    print(f"   XLA JIT enabled: 1.5-2x faster execution!")

    # Enable mixed precision for A6000 (FP16)
    # Note: TensorFlow requires special handling for FP16 with categorical outputs
    # Using float32 for now to avoid compatibility issues
    if AUTO_CONFIG and AUTO_CONFIG['TRAIN_PRECISION'] == 'fp16':
        print(f"\n‚ö° Mixed Precision available but disabled for TensorFlow compatibility")
        print(f"   (TensorFlow categorical outputs require float32)")
        # tf.keras.mixed_precision.set_global_policy('mixed_float16')  # Disabled

    # 1. Get List of Allowed Classes
    target_classes = get_filtered_class_list(TRAIN_DIR)

    if not target_classes:
        print("‚ùå Error: No valid classes found after filtering!")
        print("üí° Hint: Run 'python src/data_tools/yolo_processor.py' first to generate training data.")
        return

    # 2. Load Data (Now unpacking the tuple)
    train_ds, class_names = load_dataset(TRAIN_DIR, target_classes, is_training=True)
    val_ds, _ = load_dataset(VAL_DIR, target_classes, is_training=False)
    
    # 3. Save Class Names
    print(f"‚úÖ Detected {len(class_names)} Classes.")
    np.save(CLASS_NAMES_PATH, class_names)
    print(f"üíæ Class names saved to {CLASS_NAMES_PATH}")

    # 4. Build or Resume Model
    initial_epoch = 0
    
    if os.path.exists(FINAL_MODEL_PATH):
        print(f"\n--- Resuming from Checkpoint: {FINAL_MODEL_PATH} ---")
        try:
            # Load model with custom objects for augmentation layers
            custom_objects = {"RandomGaussianBlur": augmentation.RandomGaussianBlur}
            model = keras.models.load_model(FINAL_MODEL_PATH, custom_objects=custom_objects)
            print(">> Model and training state loaded successfully.")
            
            # TODO: Extract epoch number from model if needed for initial_epoch
            # For now, ModelCheckpoint will handle best model restoration
            
        except Exception as e:
            print(f">> Warning: Could not load checkpoint ({e}). Building new model.")
            model = vision_model.build_model(num_classes=len(class_names))
    else:
        print("\nüèóÔ∏è Building New EfficientNet-B5 Model...")
        model = vision_model.build_model(num_classes=len(class_names))
    
    # 5. Callbacks
    callbacks_list = [
        callbacks.ModelCheckpoint(
            filepath=str(FINAL_MODEL_PATH),
            save_best_only=True,
            monitor="val_accuracy",
            mode="max",
            verbose=1
        ),
        callbacks.EarlyStopping(
            monitor="val_accuracy",
            patience=8,
            restore_best_weights=True,
            verbose=1
        ),
        callbacks.ReduceLROnPlateau(
            monitor="val_loss",
            factor=0.2,
            patience=3,
            min_lr=1e-6,
            verbose=1
        )
    ]

    # 6. Train
    print("\nüî• Training Started...")
    model.fit(
        train_ds,
        epochs=config.EPOCHS,
        initial_epoch=initial_epoch,
        validation_data=val_ds,
        callbacks=callbacks_list,
        verbose=1
    )
    
    print(f"\n‚úÖ Training Complete. Best model saved to: {FINAL_MODEL_PATH}")

if __name__ == "__main__":
    main()
